{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, svm\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from imblearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Set random seed for reproducability\n",
    "np.random.seed(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in dataset\n",
    "data = pd.read_csv(\"../../data/sensitivity_data/sensitivity_dataset.csv\")\n",
    "data = data[[\"Filename\",\"Date\",\"Sensitivity\",\"Document\"]]\n",
    "\n",
    "# Train / Test split\n",
    "train_x, test_x, train_y, test_y = model_selection.train_test_split(data['Document'],data['Sensitivity'],test_size=0.2,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jack-\\AppData\\Local\\Temp/ipykernel_16092/4269885102.py:5: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  glove2word2vec(glove_path, word2vec_output_file)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(400000, 300)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "glove_path = \"..\\deep_learning\\glove.6B.300d.txt\"\n",
    "word2vec_output_file = \"glove.6B.300d\"+'.word2vec'\n",
    "glove2word2vec(glove_path, word2vec_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_output_file = \"glove.6B.300d\"+'.word2vec'\n",
    "model = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2VecVectorizer:\n",
    "  def __init__(self, model):\n",
    "    print(\"Loading in word vectors...\")\n",
    "    self.word_vectors = model\n",
    "    print(\"Finished loading in word vectors\")\n",
    "\n",
    "  def fit(self, data):\n",
    "    pass\n",
    "\n",
    "  def transform(self, data):\n",
    "    # determine the dimensionality of vectors\n",
    "    v = self.word_vectors.get_vector('king')\n",
    "    self.D = v.shape[0]\n",
    "\n",
    "    X = np.zeros((len(data), self.D))\n",
    "    n = 0\n",
    "    emptycount = 0\n",
    "    for sentence in data:\n",
    "      tokens = sentence.split()\n",
    "      vecs = []\n",
    "      m = 0\n",
    "      for word in tokens:\n",
    "        try:\n",
    "          # throws KeyError if word not found\n",
    "          vec = self.word_vectors.get_vector(word)\n",
    "          vecs.append(vec)\n",
    "          m += 1\n",
    "        except KeyError:\n",
    "          pass\n",
    "      if len(vecs) > 0:\n",
    "        vecs = np.array(vecs)\n",
    "        X[n] = vecs.mean(axis=0)\n",
    "      else:\n",
    "        emptycount += 1\n",
    "      n += 1\n",
    "    print(\"Numer of samples with no words found: %s / %s\" % (emptycount, len(data)))\n",
    "    return X\n",
    "\n",
    "\n",
    "  def fit_transform(self, data):\n",
    "    self.fit(data)\n",
    "    return self.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n",
      "Numer of samples with no words found: 4 / 3040\n",
      "Numer of samples with no words found: 0 / 761\n"
     ]
    }
   ],
   "source": [
    "vectorizer = Word2VecVectorizer(model)\n",
    "train_x = vectorizer.fit_transform(train_x)\n",
    "test_x = vectorizer.fit_transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2789115646258503 0.6386248365179112 0.3919694072657744\n"
     ]
    }
   ],
   "source": [
    "imba_pipeline = make_pipeline(RandomOverSampler(random_state=42), \n",
    "                              GaussianNB())\n",
    "                              \n",
    "kfold = model_selection.KFold(n_splits=5)\n",
    "\n",
    "scoring = {\n",
    "\"f2_score\" : make_scorer(fbeta_score, beta=2.0),\n",
    "\"precision\" : make_scorer(precision_score),\n",
    "\"bal_acc\" : make_scorer(balanced_accuracy_score)\n",
    "}\n",
    "\n",
    "imba_pipeline.fit(train_x,train_y)\n",
    "y_test_predict = imba_pipeline.predict(test_x)\n",
    "\n",
    "precision = precision_score(test_y, y_test_predict)\n",
    "bac = balanced_accuracy_score(test_y, y_test_predict)\n",
    "f2 = fbeta_score(test_y, y_test_predict, beta=2.0)\n",
    "print(precision,bac,f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2573099415204678 0.6388401543908897 0.4021937842778794\n"
     ]
    }
   ],
   "source": [
    "imba_pipeline = make_pipeline(RandomOverSampler(random_state=42), \n",
    "                              RandomForestClassifier(random_state=5))\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [50, 100, 200,400,800],\n",
    "    'max_depth': [4, 6, 10, 12,50,100,200],\n",
    "    'random_state': [5]\n",
    "}\n",
    "\n",
    "new_params = {'randomforestclassifier__' + key: params[key] for key in params}\n",
    "grid_imba = GridSearchCV(imba_pipeline, param_grid=new_params, cv=kfold, scoring='recall',\n",
    "                        return_train_score=True)\n",
    "grid_imba.fit(train_x, train_y)\n",
    "y_test_predict = grid_imba.best_estimator_.named_steps['randomforestclassifier'].predict(test_x)\n",
    "\n",
    "precision = precision_score(test_y, y_test_predict)\n",
    "bac = balanced_accuracy_score(test_y, y_test_predict)\n",
    "f2 = fbeta_score(test_y, y_test_predict, beta=2.0)\n",
    "print(precision,bac,f2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a2292f7dadeec0b36dafabb7d1d8dd7b9b8b8f0665c515bec64e67bf9650aaf0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
