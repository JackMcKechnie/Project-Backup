{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import scale\n",
    "from make_scores import make_scores\n",
    "from regression_table_significance import regression_table\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.stats.weightstats import ztest as ztest\n",
    "from statsmodels.stats.weightstats import ttest_ind as ttest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"..\\..\\data\\mturk_experiment_2.csv\",encoding=\"unicode escape\")\n",
    "feature_names = [\"Informativeness\",\"Implicature\",\"Length in Words\",\"Length in Characters\",\"F-score\",\"I-score\",\"Lexical Density\"]\n",
    "features = data[feature_names]\n",
    "target = data[\"Formality\"]\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "scoring = [\"r2\",\"neg_mean_squared_error\",\"neg_mean_absolute_error\",\"max_error\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jack-\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linear</th>\n",
       "      <th>Ridge</th>\n",
       "      <th>Lasso</th>\n",
       "      <th>LARS Lasso</th>\n",
       "      <th>Bayesian Ridge</th>\n",
       "      <th>SGD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4187</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5538</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5350</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2783</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5505</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2164</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Linear  Ridge  Lasso  LARS Lasso  Bayesian Ridge  SGD\n",
       "4187     0.4    0.4    0.4         0.4             0.4  0.4\n",
       "5538     0.5    0.5    0.5         0.5             0.5  0.5\n",
       "141      0.4    0.4    0.4         0.4             0.4  0.4\n",
       "9        0.7    0.7    0.7         0.7             0.7  0.7\n",
       "5350     0.3    0.3    0.3         0.3             0.3  0.3\n",
       "...      ...    ...    ...         ...             ...  ...\n",
       "1274     0.6    0.6    0.6         0.6             0.6  0.6\n",
       "2783     0.3    0.3    0.3         0.3             0.3  0.3\n",
       "181      0.5    0.5    0.5         0.5             0.5  0.5\n",
       "5505     0.2    0.2    0.2         0.2             0.2  0.2\n",
       "2164     0.7    0.7    0.7         0.7             0.7  0.7\n",
       "\n",
       "[1400 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SQUINKY!\n",
    "squinky = pd.read_csv(\"..\\..\\data\\mturk_experiment_2.csv\",encoding=\"unicode escape\")\n",
    "lexical = pd.read_csv(\"..\\..\\data\\squinky_lexical.csv\",encoding=\"unicode escape\")\n",
    "squinky_lexical = pd.merge(squinky,lexical)\n",
    "feature_names = [\"Informativeness\",\"Implicature\",\"Length in Words\",\"Length in Characters\",\"F-score\",\"I-score\",\"Lexical Density\"]\n",
    "features = squinky_lexical[feature_names]\n",
    "target = squinky_lexical[\"Formality\"]\n",
    "squinky_x, squinky_test_x, squinky_y, squinky_test_y = train_test_split(features, target, test_size=0.2, random_state=5)\n",
    "\n",
    "squinky_linear_predicted = np.around(linear_model.LinearRegression().fit(squinky_x, squinky_y).predict(squinky_test_x),1)\n",
    "squinky_errors = pd.DataFrame()\n",
    "squinky_errors[\"Linear\"] = abs(squinky_linear_predicted - squinky_test_y)\n",
    "\n",
    "squinky_ridge_predicted = np.around(linear_model.Ridge().fit(squinky_x, squinky_y).predict(squinky_test_x),1)\n",
    "squinky_errors[\"Ridge\"] = abs(squinky_linear_predicted - squinky_test_y)\n",
    "\n",
    "squinky_ridge_predicted = np.around(linear_model.Lasso().fit(squinky_x, squinky_y).predict(squinky_test_x),1)\n",
    "squinky_errors[\"Lasso\"] = abs(squinky_linear_predicted - squinky_test_y)\n",
    "\n",
    "squinky_ridge_predicted = np.around(linear_model.LassoLars().fit(squinky_x, squinky_y).predict(squinky_test_x),1)\n",
    "squinky_errors[\"LARS Lasso\"] = abs(squinky_linear_predicted - squinky_test_y)\n",
    "\n",
    "squinky_ridge_predicted = np.around(linear_model.BayesianRidge().fit(squinky_x, squinky_y).predict(squinky_test_x),1)\n",
    "squinky_errors[\"Bayesian Ridge\"] = abs(squinky_linear_predicted - squinky_test_y)\n",
    "\n",
    "squinky_ridge_predicted = np.around(linear_model.SGDRegressor().fit(scale(squinky_x), scale(squinky_y)).predict(scale(squinky_test_x)),1)\n",
    "squinky_errors[\"SGD\"] = abs(squinky_linear_predicted - squinky_test_y)\n",
    "\n",
    "squinky_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jack-\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linear</th>\n",
       "      <th>Ridge</th>\n",
       "      <th>Lasso</th>\n",
       "      <th>LARS Lasso</th>\n",
       "      <th>Bayesian Ridge</th>\n",
       "      <th>SGD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4187</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5538</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5350</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2783</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5505</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2164</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Linear  Ridge  Lasso  LARS Lasso  Bayesian Ridge  SGD\n",
       "4187     0.4    0.4    0.4         0.4             0.4  0.4\n",
       "5538     0.3    0.3    0.3         0.3             0.3  0.3\n",
       "141      0.4    0.4    0.4         0.4             0.4  0.4\n",
       "9        0.6    0.6    0.6         0.6             0.6  0.6\n",
       "5350     0.3    0.3    0.3         0.3             0.3  0.3\n",
       "...      ...    ...    ...         ...             ...  ...\n",
       "1274     0.5    0.5    0.5         0.5             0.5  0.5\n",
       "2783     0.3    0.3    0.3         0.3             0.3  0.3\n",
       "181      0.6    0.6    0.6         0.6             0.6  0.6\n",
       "5505     0.1    0.1    0.1         0.1             0.1  0.1\n",
       "2164     0.7    0.7    0.7         0.7             0.7  0.7\n",
       "\n",
       "[1400 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lexical\n",
    "squinky = pd.read_csv(\"..\\..\\data\\mturk_experiment_2.csv\",encoding=\"unicode escape\")\n",
    "lexical = pd.read_csv(\"..\\..\\data\\squinky_lexical.csv\",encoding=\"unicode escape\")\n",
    "squinky_lexical = pd.merge(squinky,lexical)\n",
    "feature_names = [\"Informativeness\",\"Implicature\",\"Length in Words\",\"Length in Characters\",\"F-score\",\"I-score\",\"Lexical Density\",\"Adjective Density\",\"Spellcheck Percentage\",\"Syllable Ratio\",\"Latinate vs Germanic\"]\n",
    "features = squinky_lexical[feature_names]\n",
    "target = squinky_lexical[\"Formality\"]\n",
    "lexical_x, lexical_test_x, lexical_y, lexical_test_y = train_test_split(features, target, test_size=0.2, random_state=5)\n",
    "\n",
    "lexical_linear_predicted = np.around(linear_model.LinearRegression().fit(lexical_x, lexical_y).predict(lexical_test_x),1)\n",
    "lexical_errors = pd.DataFrame()\n",
    "lexical_errors[\"Linear\"] = abs(lexical_linear_predicted - lexical_test_y)\n",
    "\n",
    "lexical_ridge_predicted = np.around(linear_model.Ridge().fit(lexical_x, lexical_y).predict(lexical_test_x),1)\n",
    "lexical_errors[\"Ridge\"] = abs(lexical_linear_predicted - lexical_test_y)\n",
    "\n",
    "lexical_ridge_predicted = np.around(linear_model.Lasso().fit(lexical_x, lexical_y).predict(lexical_test_x),1)\n",
    "lexical_errors[\"Lasso\"] = abs(lexical_linear_predicted - lexical_test_y)\n",
    "\n",
    "lexical_ridge_predicted = np.around(linear_model.LassoLars().fit(lexical_x, lexical_y).predict(lexical_test_x),1)\n",
    "lexical_errors[\"LARS Lasso\"] = abs(lexical_linear_predicted - lexical_test_y)\n",
    "\n",
    "lexical_ridge_predicted = np.around(linear_model.BayesianRidge().fit(lexical_x, lexical_y).predict(lexical_test_x),1)\n",
    "lexical_errors[\"Bayesian Ridge\"] = abs(lexical_linear_predicted - lexical_test_y)\n",
    "\n",
    "lexical_ridge_predicted = np.around(linear_model.SGDRegressor().fit(scale(lexical_x), scale(lexical_y)).predict(scale(lexical_test_x)),1)\n",
    "lexical_errors[\"SGD\"] = abs(lexical_linear_predicted - lexical_test_y)\n",
    "\n",
    "lexical_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jack-\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linear</th>\n",
       "      <th>Ridge</th>\n",
       "      <th>Lasso</th>\n",
       "      <th>LARS Lasso</th>\n",
       "      <th>Bayesian Ridge</th>\n",
       "      <th>SGD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4187</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5538</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5350</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2783</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5505</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2164</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Linear  Ridge  Lasso  LARS Lasso  Bayesian Ridge  SGD\n",
       "4187     0.5    0.5    0.5         0.5             0.5  0.5\n",
       "5538     0.4    0.4    0.4         0.4             0.4  0.4\n",
       "141      0.3    0.3    0.3         0.3             0.3  0.3\n",
       "9        0.7    0.7    0.7         0.7             0.7  0.7\n",
       "5350     0.2    0.2    0.2         0.2             0.2  0.2\n",
       "...      ...    ...    ...         ...             ...  ...\n",
       "1274     0.5    0.5    0.5         0.5             0.5  0.5\n",
       "2783     0.2    0.2    0.2         0.2             0.2  0.2\n",
       "181      0.5    0.5    0.5         0.5             0.5  0.5\n",
       "5505     0.1    0.1    0.1         0.1             0.1  0.1\n",
       "2164     0.7    0.7    0.7         0.7             0.7  0.7\n",
       "\n",
       "[1400 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scores\n",
    "squinky = pd.read_csv(\"..\\..\\data\\mturk_experiment_2.csv\",encoding=\"unicode escape\")\n",
    "scores = pd.read_csv(\"..\\..\\data\\squinky_scores.csv\",encoding=\"unicode escape\")\n",
    "squinky_scores = pd.merge(squinky,scores)\n",
    "feature_names = [\"Informativeness\",\"Implicature\",\"Length in Words\",\"Length in Characters\",\"F-score\",\"I-score\",\"Lexical Density\",\"ADF Score\",\"FK Grade Level\",\"Reading Time\",\"WF Score\"]\n",
    "features = squinky_scores[feature_names]\n",
    "target = squinky_scores[\"Formality\"]\n",
    "scores_x, scores_test_x, scores_y, scores_test_y = train_test_split(features, target, test_size=0.2, random_state=5)\n",
    "\n",
    "scores_linear_predicted = np.around(linear_model.LinearRegression().fit(scores_x, scores_y).predict(scores_test_x),1)\n",
    "scores_errors = pd.DataFrame()\n",
    "scores_errors[\"Linear\"] = abs(scores_linear_predicted - scores_test_y)\n",
    "\n",
    "scores_ridge_predicted = np.around(linear_model.Ridge().fit(scores_x, scores_y).predict(scores_test_x),1)\n",
    "scores_errors[\"Ridge\"] = abs(scores_linear_predicted - scores_test_y)\n",
    "\n",
    "scores_ridge_predicted = np.around(linear_model.Lasso().fit(scores_x, scores_y).predict(scores_test_x),1)\n",
    "scores_errors[\"Lasso\"] = abs(scores_linear_predicted - scores_test_y)\n",
    "\n",
    "scores_ridge_predicted = np.around(linear_model.LassoLars().fit(scores_x, scores_y).predict(scores_test_x),1)\n",
    "scores_errors[\"LARS Lasso\"] = abs(scores_linear_predicted - scores_test_y)\n",
    "\n",
    "scores_ridge_predicted = np.around(linear_model.BayesianRidge().fit(scores_x, scores_y).predict(scores_test_x),1)\n",
    "scores_errors[\"Bayesian Ridge\"] = abs(scores_linear_predicted - scores_test_y)\n",
    "\n",
    "scores_ridge_predicted = np.around(linear_model.SGDRegressor().fit(scale(scores_x), scale(scores_y)).predict(scale(scores_test_x)),1)\n",
    "scores_errors[\"SGD\"] = abs(scores_linear_predicted - scores_test_y)\n",
    "\n",
    "scores_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jack-\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linear</th>\n",
       "      <th>Ridge</th>\n",
       "      <th>Lasso</th>\n",
       "      <th>LARS Lasso</th>\n",
       "      <th>Bayesian Ridge</th>\n",
       "      <th>SGD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4187</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5538</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5350</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2783</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5505</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2164</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Linear  Ridge  Lasso  LARS Lasso  Bayesian Ridge  SGD\n",
       "4187     0.5    0.5    0.5         0.5             0.5  0.5\n",
       "5538     0.4    0.4    0.4         0.4             0.4  0.4\n",
       "141      0.3    0.3    0.3         0.3             0.3  0.3\n",
       "9        0.5    0.5    0.5         0.5             0.5  0.5\n",
       "5350     0.2    0.2    0.2         0.2             0.2  0.2\n",
       "...      ...    ...    ...         ...             ...  ...\n",
       "1274     0.4    0.4    0.4         0.4             0.4  0.4\n",
       "2783     0.2    0.2    0.2         0.2             0.2  0.2\n",
       "181      0.4    0.4    0.4         0.4             0.4  0.4\n",
       "5505     0.2    0.2    0.2         0.2             0.2  0.2\n",
       "2164     0.6    0.6    0.6         0.6             0.6  0.6\n",
       "\n",
       "[1400 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nlp\n",
    "squinky = pd.read_csv(\"..\\..\\data\\mturk_experiment_2.csv\",encoding=\"unicode escape\")\n",
    "reading = pd.read_csv(\"../../data/squinky_reading.csv\",encoding=\"unicode escape\")\n",
    "squinky_reading = pd.merge(squinky,reading)\n",
    "feature_names = [\"Informativeness\",\"Implicature\",\"Length in Words\",\"Length in Characters\",\"F-score\",\"I-score\",\"Lexical Density\",\"FK Reading Ease\",\"FOG Scale\",\"SMOG Index\",\"ARI\",\"CL Index\",\"LW Formula\",\"DC Score\",\"Readability Consensus\",\"Spache Formula\"]\n",
    "features = squinky_reading[feature_names]\n",
    "target = squinky_reading[\"Formality\"]\n",
    "reading_x, reading_test_x, reading_y, reading_test_y = train_test_split(features, target, test_size=0.2, random_state=5)\n",
    "\n",
    "reading_linear_predicted = np.around(linear_model.LinearRegression().fit(reading_x, reading_y).predict(reading_test_x),1)\n",
    "reading_errors = pd.DataFrame()\n",
    "reading_errors[\"Linear\"] = abs(reading_linear_predicted - reading_test_y)\n",
    "\n",
    "reading_ridge_predicted = np.around(linear_model.Ridge().fit(reading_x, reading_y).predict(reading_test_x),1)\n",
    "reading_errors[\"Ridge\"] = abs(reading_linear_predicted - reading_test_y)\n",
    "\n",
    "reading_ridge_predicted = np.around(linear_model.Lasso().fit(reading_x, reading_y).predict(reading_test_x),1)\n",
    "reading_errors[\"Lasso\"] = abs(reading_linear_predicted - reading_test_y)\n",
    "\n",
    "reading_ridge_predicted = np.around(linear_model.LassoLars().fit(reading_x, reading_y).predict(reading_test_x),1)\n",
    "reading_errors[\"LARS Lasso\"] = abs(reading_linear_predicted - reading_test_y)\n",
    "\n",
    "reading_ridge_predicted = np.around(linear_model.BayesianRidge().fit(reading_x, reading_y).predict(reading_test_x),1)\n",
    "reading_errors[\"Bayesian Ridge\"] = abs(reading_linear_predicted - reading_test_y)\n",
    "\n",
    "reading_ridge_predicted = np.around(linear_model.SGDRegressor().fit(scale(reading_x), scale(reading_y)).predict(scale(reading_test_x)),1)\n",
    "reading_errors[\"SGD\"] = abs(reading_linear_predicted - reading_test_y)\n",
    "\n",
    "reading_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jack-\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "C:\\Users\\jack-\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\base.py:441: UserWarning: X does not have valid feature names, but SGDRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linear</th>\n",
       "      <th>Ridge</th>\n",
       "      <th>Lasso</th>\n",
       "      <th>LARS Lasso</th>\n",
       "      <th>Bayesian Ridge</th>\n",
       "      <th>SGD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4187</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5538</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5350</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2783</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5505</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2164</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Linear  Ridge  Lasso  LARS Lasso  Bayesian Ridge  SGD\n",
       "4187     0.4    0.4    0.4         0.4             0.4  0.4\n",
       "5538     0.5    0.5    0.5         0.5             0.5  0.5\n",
       "141      0.3    0.3    0.3         0.3             0.3  0.3\n",
       "9        0.6    0.6    0.6         0.6             0.6  0.6\n",
       "5350     0.3    0.3    0.3         0.3             0.3  0.3\n",
       "...      ...    ...    ...         ...             ...  ...\n",
       "1274     0.6    0.6    0.6         0.6             0.6  0.6\n",
       "2783     0.3    0.3    0.3         0.3             0.3  0.3\n",
       "181      0.5    0.5    0.5         0.5             0.5  0.5\n",
       "5505     0.1    0.1    0.1         0.1             0.1  0.1\n",
       "2164     0.7    0.7    0.7         0.7             0.7  0.7\n",
       "\n",
       "[1400 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLP\n",
    "squinky = pd.read_csv(\"..\\..\\data\\mturk_experiment_2.csv\",encoding=\"unicode escape\")\n",
    "nlp = pd.read_csv(\"..\\..\\data\\\\squinky_nlp.csv\",encoding=\"unicode escape\")\n",
    "squinky_nlp = pd.merge(squinky,nlp)\n",
    "feature_names = [\"Informativeness\",\"Implicature\",\"Length in Words\",\"Length in Characters\",\"F-score\",\"I-score\",\"Lexical Density\",\"Cluster\",\"Topic\"]\n",
    "features = squinky_nlp[feature_names]\n",
    "target = squinky_nlp[\"Formality\"]\n",
    "nlp_x, nlp_test_x, nlp_y, nlp_test_y = train_test_split(features, target, test_size=0.2, random_state=5)\n",
    "\n",
    "nlp_linear_predicted = np.around(linear_model.LinearRegression().fit(nlp_x, nlp_y).predict(nlp_test_x),1)\n",
    "nlp_errors = pd.DataFrame()\n",
    "nlp_errors[\"Linear\"] = abs(nlp_linear_predicted - nlp_test_y)\n",
    "\n",
    "nlp_ridge_predicted = np.around(linear_model.Ridge().fit(nlp_x, nlp_y).predict(nlp_test_x),1)\n",
    "nlp_errors[\"Ridge\"] = abs(nlp_linear_predicted - nlp_test_y)\n",
    "\n",
    "nlp_ridge_predicted = np.around(linear_model.Lasso().fit(nlp_x, nlp_y).predict(nlp_test_x),1)\n",
    "nlp_errors[\"Lasso\"] = abs(nlp_linear_predicted - nlp_test_y)\n",
    "\n",
    "nlp_ridge_predicted = np.around(linear_model.LassoLars().fit(nlp_x, nlp_y).predict(nlp_test_x),1)\n",
    "nlp_errors[\"LARS Lasso\"] = abs(nlp_linear_predicted - nlp_test_y)\n",
    "\n",
    "nlp_ridge_predicted = np.around(linear_model.BayesianRidge().fit(nlp_x, nlp_y).predict(nlp_test_x),1)\n",
    "nlp_errors[\"Bayesian Ridge\"] = abs(nlp_linear_predicted - nlp_test_y)\n",
    "\n",
    "nlp_ridge_predicted = np.around(linear_model.SGDRegressor().fit(nlp_x, nlp_y).predict(scale(nlp_test_x)),1)\n",
    "nlp_errors[\"SGD\"] = abs(nlp_linear_predicted - nlp_test_y)\n",
    "\n",
    "nlp_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear\n",
      "0.5085140195658864\n",
      "0.956252461107937\n",
      "0.6960401088548002\n",
      "0.8891961843718229\n",
      "Ridge\n",
      "0.5085140195658864\n",
      "0.956252461107937\n",
      "0.6960401088548002\n",
      "0.8891961843718229\n",
      "Lasso\n",
      "0.5085140195658864\n",
      "0.956252461107937\n",
      "0.6960401088548002\n",
      "0.8891961843718229\n",
      "LARS Lasso\n",
      "0.5085140195658864\n",
      "0.956252461107937\n",
      "0.6960401088548002\n",
      "0.8891961843718229\n",
      "Bayesian Ridge\n",
      "0.5085140195658864\n",
      "0.956252461107937\n",
      "0.6960401088548002\n",
      "0.8891961843718229\n",
      "SGD\n",
      "0.5085140195658864\n",
      "0.956252461107937\n",
      "0.6960401088548002\n",
      "0.8891961843718229\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T-Statistic</th>\n",
       "      <th>P-Value</th>\n",
       "      <th>DF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear - Squinky / Lexical</th>\n",
       "      <td>0.661238</td>\n",
       "      <td>0.508514</td>\n",
       "      <td>2798.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear - Squinky / Scores</th>\n",
       "      <td>0.054862</td>\n",
       "      <td>0.956252</td>\n",
       "      <td>2798.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear - Squinky / Reading</th>\n",
       "      <td>0.390712</td>\n",
       "      <td>0.696040</td>\n",
       "      <td>2798.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear - Squinky / NLP</th>\n",
       "      <td>-0.139334</td>\n",
       "      <td>0.889196</td>\n",
       "      <td>2798.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge - Squinky / Lexical</th>\n",
       "      <td>0.661238</td>\n",
       "      <td>0.508514</td>\n",
       "      <td>2798.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge - Squinky / Scores</th>\n",
       "      <td>0.054862</td>\n",
       "      <td>0.956252</td>\n",
       "      <td>2798.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge - Squinky / Reading</th>\n",
       "      <td>0.390712</td>\n",
       "      <td>0.696040</td>\n",
       "      <td>2798.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge - Squinky / NLP</th>\n",
       "      <td>-0.139334</td>\n",
       "      <td>0.889196</td>\n",
       "      <td>2798.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso - Squinky / Lexical</th>\n",
       "      <td>0.661238</td>\n",
       "      <td>0.508514</td>\n",
       "      <td>2798.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso - Squinky / Scores</th>\n",
       "      <td>0.054862</td>\n",
       "      <td>0.956252</td>\n",
       "      <td>2798.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso - Squinky / Reading</th>\n",
       "      <td>0.390712</td>\n",
       "      <td>0.696040</td>\n",
       "      <td>2798.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso - Squinky / NLP</th>\n",
       "      <td>-0.139334</td>\n",
       "      <td>0.889196</td>\n",
       "      <td>2798.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LARS Lasso - Squinky / Lexical</th>\n",
       "      <td>0.661238</td>\n",
       "      <td>0.508514</td>\n",
       "      <td>2798.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LARS Lasso - Squinky / Scores</th>\n",
       "      <td>0.054862</td>\n",
       "      <td>0.956252</td>\n",
       "      <td>2798.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LARS Lasso - Squinky / Reading</th>\n",
       "      <td>0.390712</td>\n",
       "      <td>0.696040</td>\n",
       "      <td>2798.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LARS Lasso - Squinky / NLP</th>\n",
       "      <td>-0.139334</td>\n",
       "      <td>0.889196</td>\n",
       "      <td>2798.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bayesian Ridge - Squinky / Lexical</th>\n",
       "      <td>0.661238</td>\n",
       "      <td>0.508514</td>\n",
       "      <td>2798.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bayesian Ridge - Squinky / Scores</th>\n",
       "      <td>0.054862</td>\n",
       "      <td>0.956252</td>\n",
       "      <td>2798.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bayesian Ridge - Squinky / Reading</th>\n",
       "      <td>0.390712</td>\n",
       "      <td>0.696040</td>\n",
       "      <td>2798.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bayesian Ridge - Squinky / NLP</th>\n",
       "      <td>-0.139334</td>\n",
       "      <td>0.889196</td>\n",
       "      <td>2798.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD - Squinky / Lexical</th>\n",
       "      <td>0.661238</td>\n",
       "      <td>0.508514</td>\n",
       "      <td>2798.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD - Squinky / Scores</th>\n",
       "      <td>0.054862</td>\n",
       "      <td>0.956252</td>\n",
       "      <td>2798.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD - Squinky / Reading</th>\n",
       "      <td>0.390712</td>\n",
       "      <td>0.696040</td>\n",
       "      <td>2798.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD - Squinky / NLP</th>\n",
       "      <td>-0.139334</td>\n",
       "      <td>0.889196</td>\n",
       "      <td>2798.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    T-Statistic   P-Value      DF\n",
       "Linear - Squinky / Lexical             0.661238  0.508514  2798.0\n",
       "Linear - Squinky / Scores              0.054862  0.956252  2798.0\n",
       "Linear - Squinky / Reading             0.390712  0.696040  2798.0\n",
       "Linear - Squinky / NLP                -0.139334  0.889196  2798.0\n",
       "Ridge - Squinky / Lexical              0.661238  0.508514  2798.0\n",
       "Ridge - Squinky / Scores               0.054862  0.956252  2798.0\n",
       "Ridge - Squinky / Reading              0.390712  0.696040  2798.0\n",
       "Ridge - Squinky / NLP                 -0.139334  0.889196  2798.0\n",
       "Lasso - Squinky / Lexical              0.661238  0.508514  2798.0\n",
       "Lasso - Squinky / Scores               0.054862  0.956252  2798.0\n",
       "Lasso - Squinky / Reading              0.390712  0.696040  2798.0\n",
       "Lasso - Squinky / NLP                 -0.139334  0.889196  2798.0\n",
       "LARS Lasso - Squinky / Lexical         0.661238  0.508514  2798.0\n",
       "LARS Lasso - Squinky / Scores          0.054862  0.956252  2798.0\n",
       "LARS Lasso - Squinky / Reading         0.390712  0.696040  2798.0\n",
       "LARS Lasso - Squinky / NLP            -0.139334  0.889196  2798.0\n",
       "Bayesian Ridge - Squinky / Lexical     0.661238  0.508514  2798.0\n",
       "Bayesian Ridge - Squinky / Scores      0.054862  0.956252  2798.0\n",
       "Bayesian Ridge - Squinky / Reading     0.390712  0.696040  2798.0\n",
       "Bayesian Ridge - Squinky / NLP        -0.139334  0.889196  2798.0\n",
       "SGD - Squinky / Lexical                0.661238  0.508514  2798.0\n",
       "SGD - Squinky / Scores                 0.054862  0.956252  2798.0\n",
       "SGD - Squinky / Reading                0.390712  0.696040  2798.0\n",
       "SGD - Squinky / NLP                   -0.139334  0.889196  2798.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "results[\"Linear - Squinky / Lexical\"] = ttest(squinky_errors[\"Linear\"],lexical_errors[\"Linear\"])\n",
    "results[\"Linear - Squinky / Scores\"] = ttest(squinky_errors[\"Linear\"],scores_errors[\"Linear\"])\n",
    "results[\"Linear - Squinky / Reading\"] = ttest(squinky_errors[\"Linear\"],reading_errors[\"Linear\"])\n",
    "results[\"Linear - Squinky / NLP\"] = ttest(squinky_errors[\"Linear\"],nlp_errors[\"Linear\"])\n",
    "\n",
    "results[\"Ridge - Squinky / Lexical\"] = ttest(squinky_errors[\"Ridge\"],lexical_errors[\"Ridge\"])\n",
    "results[\"Ridge - Squinky / Scores\"] = ttest(squinky_errors[\"Ridge\"],scores_errors[\"Ridge\"])\n",
    "results[\"Ridge - Squinky / Reading\"] = ttest(squinky_errors[\"Ridge\"],reading_errors[\"Ridge\"])\n",
    "results[\"Ridge - Squinky / NLP\"] = ttest(squinky_errors[\"Ridge\"],nlp_errors[\"Ridge\"])\n",
    "\n",
    "results[\"Lasso - Squinky / Lexical\"] = ttest(squinky_errors[\"Lasso\"],lexical_errors[\"Lasso\"])\n",
    "results[\"Lasso - Squinky / Scores\"] = ttest(squinky_errors[\"Lasso\"],scores_errors[\"Lasso\"])\n",
    "results[\"Lasso - Squinky / Reading\"] = ttest(squinky_errors[\"Lasso\"],reading_errors[\"Lasso\"])\n",
    "results[\"Lasso - Squinky / NLP\"] = ttest(squinky_errors[\"Lasso\"],nlp_errors[\"Lasso\"])\n",
    "\n",
    "results[\"LARS Lasso - Squinky / Lexical\"] = ttest(squinky_errors[\"LARS Lasso\"],lexical_errors[\"LARS Lasso\"])\n",
    "results[\"LARS Lasso - Squinky / Scores\"] = ttest(squinky_errors[\"LARS Lasso\"],scores_errors[\"LARS Lasso\"])\n",
    "results[\"LARS Lasso - Squinky / Reading\"] = ttest(squinky_errors[\"LARS Lasso\"],reading_errors[\"LARS Lasso\"])\n",
    "results[\"LARS Lasso - Squinky / NLP\"] = ttest(squinky_errors[\"LARS Lasso\"],nlp_errors[\"LARS Lasso\"])\n",
    "\n",
    "results[\"Bayesian Ridge - Squinky / Lexical\"] = ttest(squinky_errors[\"Bayesian Ridge\"],lexical_errors[\"Bayesian Ridge\"])\n",
    "results[\"Bayesian Ridge - Squinky / Scores\"] = ttest(squinky_errors[\"Bayesian Ridge\"],scores_errors[\"Bayesian Ridge\"])\n",
    "results[\"Bayesian Ridge - Squinky / Reading\"] = ttest(squinky_errors[\"Bayesian Ridge\"],reading_errors[\"Bayesian Ridge\"])\n",
    "results[\"Bayesian Ridge - Squinky / NLP\"] = ttest(squinky_errors[\"Bayesian Ridge\"],nlp_errors[\"Bayesian Ridge\"])\n",
    "\n",
    "results[\"SGD - Squinky / Lexical\"] = ttest(squinky_errors[\"SGD\"],lexical_errors[\"SGD\"])\n",
    "results[\"SGD - Squinky / Scores\"] = ttest(squinky_errors[\"SGD\"],scores_errors[\"SGD\"])\n",
    "results[\"SGD - Squinky / Reading\"] = ttest(squinky_errors[\"SGD\"],reading_errors[\"SGD\"])\n",
    "results[\"SGD - Squinky / NLP\"] = ttest(squinky_errors[\"SGD\"],nlp_errors[\"SGD\"])\n",
    "\n",
    "\n",
    "print(\"Linear\")\n",
    "print(ttest(squinky_errors[\"Linear\"],lexical_errors[\"Linear\"])[1])\n",
    "print(ttest(squinky_errors[\"Linear\"],scores_errors[\"Linear\"])[1])\n",
    "print(ttest(squinky_errors[\"Linear\"],reading_errors[\"Linear\"])[1])\n",
    "print(ttest(squinky_errors[\"Linear\"],nlp_errors[\"Linear\"])[1])\n",
    "\n",
    "print(\"Ridge\")\n",
    "print(ttest(squinky_errors[\"Ridge\"],lexical_errors[\"Ridge\"])[1])\n",
    "print(ttest(squinky_errors[\"Ridge\"],scores_errors[\"Ridge\"])[1])\n",
    "print(ttest(squinky_errors[\"Ridge\"],reading_errors[\"Ridge\"])[1])\n",
    "print(ttest(squinky_errors[\"Ridge\"],nlp_errors[\"Ridge\"])[1])\n",
    "\n",
    "print(\"Lasso\")\n",
    "print(ttest(squinky_errors[\"Lasso\"],lexical_errors[\"Lasso\"])[1])\n",
    "print(ttest(squinky_errors[\"Lasso\"],scores_errors[\"Lasso\"])[1])\n",
    "print(ttest(squinky_errors[\"Lasso\"],reading_errors[\"Lasso\"])[1])\n",
    "print(ttest(squinky_errors[\"Lasso\"],nlp_errors[\"Lasso\"])[1])\n",
    "\n",
    "print(\"LARS Lasso\")\n",
    "print(ttest(squinky_errors[\"LARS Lasso\"],lexical_errors[\"LARS Lasso\"])[1])\n",
    "print(ttest(squinky_errors[\"LARS Lasso\"],scores_errors[\"LARS Lasso\"])[1])\n",
    "print(ttest(squinky_errors[\"LARS Lasso\"],reading_errors[\"LARS Lasso\"])[1])\n",
    "print(ttest(squinky_errors[\"LARS Lasso\"],nlp_errors[\"LARS Lasso\"])[1])\n",
    "\n",
    "print(\"Bayesian Ridge\")\n",
    "print(ttest(squinky_errors[\"Bayesian Ridge\"],lexical_errors[\"Bayesian Ridge\"])[1])\n",
    "print(ttest(squinky_errors[\"Bayesian Ridge\"],scores_errors[\"Bayesian Ridge\"])[1])\n",
    "print(ttest(squinky_errors[\"Bayesian Ridge\"],reading_errors[\"Bayesian Ridge\"])[1])\n",
    "print(ttest(squinky_errors[\"Bayesian Ridge\"],nlp_errors[\"Bayesian Ridge\"])[1])\n",
    "\n",
    "print(\"SGD\")\n",
    "print(ttest(squinky_errors[\"SGD\"],lexical_errors[\"SGD\"])[1])\n",
    "print(ttest(squinky_errors[\"SGD\"],scores_errors[\"SGD\"])[1])\n",
    "print(ttest(squinky_errors[\"SGD\"],reading_errors[\"SGD\"])[1])\n",
    "print(ttest(squinky_errors[\"SGD\"],nlp_errors[\"SGD\"])[1])\n",
    "\n",
    "\n",
    "results = results.T\n",
    "results.columns = [\"T-Statistic\",\"P-Value\",\"DF\"]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear\n",
      "0.5084595761282691\n",
      "0.9562485442774085\n",
      "0.6960103636062784\n",
      "0.8891861565882786\n",
      "Ridge\n",
      "0.5084595761282691\n",
      "0.9562485442774085\n",
      "0.6960103636062784\n",
      "0.8891861565882786\n",
      "Lasso\n",
      "0.5084595761282691\n",
      "0.9562485442774085\n",
      "0.6960103636062784\n",
      "0.8891861565882786\n",
      "LARS Lasso\n",
      "0.5084595761282691\n",
      "0.9562485442774085\n",
      "0.6960103636062784\n",
      "0.8891861565882786\n",
      "Bayesian Ridge\n",
      "0.5084595761282691\n",
      "0.9562485442774085\n",
      "0.6960103636062784\n",
      "0.8891861565882786\n",
      "SGD\n",
      "0.5084595761282691\n",
      "0.9562485442774085\n",
      "0.6960103636062784\n",
      "0.8891861565882786\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T-Statistic</th>\n",
       "      <th>P-Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear - Squinky / Lexical</th>\n",
       "      <td>0.661238</td>\n",
       "      <td>0.508460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear - Squinky / Scores</th>\n",
       "      <td>0.054862</td>\n",
       "      <td>0.956249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear - Squinky / Reading</th>\n",
       "      <td>0.390712</td>\n",
       "      <td>0.696010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear - Squinky / NLP</th>\n",
       "      <td>-0.139334</td>\n",
       "      <td>0.889186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge - Squinky / Lexical</th>\n",
       "      <td>0.661238</td>\n",
       "      <td>0.508460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge - Squinky / Scores</th>\n",
       "      <td>0.054862</td>\n",
       "      <td>0.956249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge - Squinky / Reading</th>\n",
       "      <td>0.390712</td>\n",
       "      <td>0.696010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge - Squinky / NLP</th>\n",
       "      <td>-0.139334</td>\n",
       "      <td>0.889186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso - Squinky / Lexical</th>\n",
       "      <td>0.661238</td>\n",
       "      <td>0.508460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso - Squinky / Scores</th>\n",
       "      <td>0.054862</td>\n",
       "      <td>0.956249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso - Squinky / Reading</th>\n",
       "      <td>0.390712</td>\n",
       "      <td>0.696010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso - Squinky / NLP</th>\n",
       "      <td>-0.139334</td>\n",
       "      <td>0.889186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LARS Lasso - Squinky / Lexical</th>\n",
       "      <td>0.661238</td>\n",
       "      <td>0.508460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LARS Lasso - Squinky / Scores</th>\n",
       "      <td>0.054862</td>\n",
       "      <td>0.956249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LARS Lasso - Squinky / Reading</th>\n",
       "      <td>0.390712</td>\n",
       "      <td>0.696010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LARS Lasso - Squinky / NLP</th>\n",
       "      <td>-0.139334</td>\n",
       "      <td>0.889186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bayesian Ridge - Squinky / Lexical</th>\n",
       "      <td>0.661238</td>\n",
       "      <td>0.508460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bayesian Ridge - Squinky / Scores</th>\n",
       "      <td>0.054862</td>\n",
       "      <td>0.956249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bayesian Ridge - Squinky / Reading</th>\n",
       "      <td>0.390712</td>\n",
       "      <td>0.696010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bayesian Ridge - Squinky / NLP</th>\n",
       "      <td>-0.139334</td>\n",
       "      <td>0.889186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD - Squinky / Lexical</th>\n",
       "      <td>0.661238</td>\n",
       "      <td>0.508460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD - Squinky / Scores</th>\n",
       "      <td>0.054862</td>\n",
       "      <td>0.956249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD - Squinky / Reading</th>\n",
       "      <td>0.390712</td>\n",
       "      <td>0.696010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD - Squinky / NLP</th>\n",
       "      <td>-0.139334</td>\n",
       "      <td>0.889186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    T-Statistic   P-Value\n",
       "Linear - Squinky / Lexical             0.661238  0.508460\n",
       "Linear - Squinky / Scores              0.054862  0.956249\n",
       "Linear - Squinky / Reading             0.390712  0.696010\n",
       "Linear - Squinky / NLP                -0.139334  0.889186\n",
       "Ridge - Squinky / Lexical              0.661238  0.508460\n",
       "Ridge - Squinky / Scores               0.054862  0.956249\n",
       "Ridge - Squinky / Reading              0.390712  0.696010\n",
       "Ridge - Squinky / NLP                 -0.139334  0.889186\n",
       "Lasso - Squinky / Lexical              0.661238  0.508460\n",
       "Lasso - Squinky / Scores               0.054862  0.956249\n",
       "Lasso - Squinky / Reading              0.390712  0.696010\n",
       "Lasso - Squinky / NLP                 -0.139334  0.889186\n",
       "LARS Lasso - Squinky / Lexical         0.661238  0.508460\n",
       "LARS Lasso - Squinky / Scores          0.054862  0.956249\n",
       "LARS Lasso - Squinky / Reading         0.390712  0.696010\n",
       "LARS Lasso - Squinky / NLP            -0.139334  0.889186\n",
       "Bayesian Ridge - Squinky / Lexical     0.661238  0.508460\n",
       "Bayesian Ridge - Squinky / Scores      0.054862  0.956249\n",
       "Bayesian Ridge - Squinky / Reading     0.390712  0.696010\n",
       "Bayesian Ridge - Squinky / NLP        -0.139334  0.889186\n",
       "SGD - Squinky / Lexical                0.661238  0.508460\n",
       "SGD - Squinky / Scores                 0.054862  0.956249\n",
       "SGD - Squinky / Reading                0.390712  0.696010\n",
       "SGD - Squinky / NLP                   -0.139334  0.889186"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "results[\"Linear - Squinky / Lexical\"] = ztest(squinky_errors[\"Linear\"],lexical_errors[\"Linear\"])\n",
    "results[\"Linear - Squinky / Scores\"] = ztest(squinky_errors[\"Linear\"],scores_errors[\"Linear\"])\n",
    "results[\"Linear - Squinky / Reading\"] = ztest(squinky_errors[\"Linear\"],reading_errors[\"Linear\"])\n",
    "results[\"Linear - Squinky / NLP\"] = ztest(squinky_errors[\"Linear\"],nlp_errors[\"Linear\"])\n",
    "\n",
    "results[\"Ridge - Squinky / Lexical\"] = ztest(squinky_errors[\"Ridge\"],lexical_errors[\"Ridge\"])\n",
    "results[\"Ridge - Squinky / Scores\"] = ztest(squinky_errors[\"Ridge\"],scores_errors[\"Ridge\"])\n",
    "results[\"Ridge - Squinky / Reading\"] = ztest(squinky_errors[\"Ridge\"],reading_errors[\"Ridge\"])\n",
    "results[\"Ridge - Squinky / NLP\"] = ztest(squinky_errors[\"Ridge\"],nlp_errors[\"Ridge\"])\n",
    "\n",
    "results[\"Lasso - Squinky / Lexical\"] = ztest(squinky_errors[\"Lasso\"],lexical_errors[\"Lasso\"])\n",
    "results[\"Lasso - Squinky / Scores\"] = ztest(squinky_errors[\"Lasso\"],scores_errors[\"Lasso\"])\n",
    "results[\"Lasso - Squinky / Reading\"] = ztest(squinky_errors[\"Lasso\"],reading_errors[\"Lasso\"])\n",
    "results[\"Lasso - Squinky / NLP\"] = ztest(squinky_errors[\"Lasso\"],nlp_errors[\"Lasso\"])\n",
    "\n",
    "results[\"LARS Lasso - Squinky / Lexical\"] = ztest(squinky_errors[\"LARS Lasso\"],lexical_errors[\"LARS Lasso\"])\n",
    "results[\"LARS Lasso - Squinky / Scores\"] = ztest(squinky_errors[\"LARS Lasso\"],scores_errors[\"LARS Lasso\"])\n",
    "results[\"LARS Lasso - Squinky / Reading\"] = ztest(squinky_errors[\"LARS Lasso\"],reading_errors[\"LARS Lasso\"])\n",
    "results[\"LARS Lasso - Squinky / NLP\"] = ztest(squinky_errors[\"LARS Lasso\"],nlp_errors[\"LARS Lasso\"])\n",
    "\n",
    "results[\"Bayesian Ridge - Squinky / Lexical\"] = ztest(squinky_errors[\"Bayesian Ridge\"],lexical_errors[\"Bayesian Ridge\"])\n",
    "results[\"Bayesian Ridge - Squinky / Scores\"] = ztest(squinky_errors[\"Bayesian Ridge\"],scores_errors[\"Bayesian Ridge\"])\n",
    "results[\"Bayesian Ridge - Squinky / Reading\"] = ztest(squinky_errors[\"Bayesian Ridge\"],reading_errors[\"Bayesian Ridge\"])\n",
    "results[\"Bayesian Ridge - Squinky / NLP\"] = ztest(squinky_errors[\"Bayesian Ridge\"],nlp_errors[\"Bayesian Ridge\"])\n",
    "\n",
    "results[\"SGD - Squinky / Lexical\"] = ztest(squinky_errors[\"SGD\"],lexical_errors[\"SGD\"])\n",
    "results[\"SGD - Squinky / Scores\"] = ztest(squinky_errors[\"SGD\"],scores_errors[\"SGD\"])\n",
    "results[\"SGD - Squinky / Reading\"] = ztest(squinky_errors[\"SGD\"],reading_errors[\"SGD\"])\n",
    "results[\"SGD - Squinky / NLP\"] = ztest(squinky_errors[\"SGD\"],nlp_errors[\"SGD\"])\n",
    "\n",
    "\n",
    "print(\"Linear\")\n",
    "print(ztest(squinky_errors[\"Linear\"],lexical_errors[\"Linear\"])[1])\n",
    "print(ztest(squinky_errors[\"Linear\"],scores_errors[\"Linear\"])[1])\n",
    "print(ztest(squinky_errors[\"Linear\"],reading_errors[\"Linear\"])[1])\n",
    "print(ztest(squinky_errors[\"Linear\"],nlp_errors[\"Linear\"])[1])\n",
    "\n",
    "print(\"Ridge\")\n",
    "print(ztest(squinky_errors[\"Ridge\"],lexical_errors[\"Ridge\"])[1])\n",
    "print(ztest(squinky_errors[\"Ridge\"],scores_errors[\"Ridge\"])[1])\n",
    "print(ztest(squinky_errors[\"Ridge\"],reading_errors[\"Ridge\"])[1])\n",
    "print(ztest(squinky_errors[\"Ridge\"],nlp_errors[\"Ridge\"])[1])\n",
    "\n",
    "print(\"Lasso\")\n",
    "print(ztest(squinky_errors[\"Lasso\"],lexical_errors[\"Lasso\"])[1])\n",
    "print(ztest(squinky_errors[\"Lasso\"],scores_errors[\"Lasso\"])[1])\n",
    "print(ztest(squinky_errors[\"Lasso\"],reading_errors[\"Lasso\"])[1])\n",
    "print(ztest(squinky_errors[\"Lasso\"],nlp_errors[\"Lasso\"])[1])\n",
    "\n",
    "print(\"LARS Lasso\")\n",
    "print(ztest(squinky_errors[\"LARS Lasso\"],lexical_errors[\"LARS Lasso\"])[1])\n",
    "print(ztest(squinky_errors[\"LARS Lasso\"],scores_errors[\"LARS Lasso\"])[1])\n",
    "print(ztest(squinky_errors[\"LARS Lasso\"],reading_errors[\"LARS Lasso\"])[1])\n",
    "print(ztest(squinky_errors[\"LARS Lasso\"],nlp_errors[\"LARS Lasso\"])[1])\n",
    "\n",
    "print(\"Bayesian Ridge\")\n",
    "print(ztest(squinky_errors[\"Bayesian Ridge\"],lexical_errors[\"Bayesian Ridge\"])[1])\n",
    "print(ztest(squinky_errors[\"Bayesian Ridge\"],scores_errors[\"Bayesian Ridge\"])[1])\n",
    "print(ztest(squinky_errors[\"Bayesian Ridge\"],reading_errors[\"Bayesian Ridge\"])[1])\n",
    "print(ztest(squinky_errors[\"Bayesian Ridge\"],nlp_errors[\"Bayesian Ridge\"])[1])\n",
    "\n",
    "print(\"SGD\")\n",
    "print(ztest(squinky_errors[\"SGD\"],lexical_errors[\"SGD\"])[1])\n",
    "print(ztest(squinky_errors[\"SGD\"],scores_errors[\"SGD\"])[1])\n",
    "print(ztest(squinky_errors[\"SGD\"],reading_errors[\"SGD\"])[1])\n",
    "print(ztest(squinky_errors[\"SGD\"],nlp_errors[\"SGD\"])[1])\n",
    "\n",
    "\n",
    "results = results.T\n",
    "results.columns = [\"T-Statistic\",\"P-Value\"]\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a2292f7dadeec0b36dafabb7d1d8dd7b9b8b8f0665c515bec64e67bf9650aaf0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
