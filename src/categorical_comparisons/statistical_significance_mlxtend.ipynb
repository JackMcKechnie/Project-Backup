{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import scale\n",
    "from make_scores import make_scores\n",
    "from regression_table_significance import regression_table\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"..\\..\\data\\mturk_experiment_2.csv\",encoding=\"unicode escape\")\n",
    "feature_names = [\"Informativeness\",\"Implicature\",\"Length in Words\",\"Length in Characters\",\"F-score\",\"I-score\",\"Lexical Density\"]\n",
    "features = data[feature_names]\n",
    "target = data[\"Formality\"]\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "scoring = [\"r2\",\"neg_mean_squared_error\",\"neg_mean_absolute_error\",\"max_error\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "\n",
    "#SQUINKY!\n",
    "squinky = pd.read_csv(\"..\\..\\data\\mturk_experiment_2.csv\",encoding=\"unicode escape\")\n",
    "lexical = pd.read_csv(\"..\\..\\data\\squinky_lexical.csv\",encoding=\"unicode escape\")\n",
    "squinky_lexical = pd.merge(squinky,lexical)\n",
    "feature_names = [\"Informativeness\",\"Implicature\",\"Length in Words\",\"Length in Characters\",\"F-score\",\"I-score\",\"Lexical Density\"]\n",
    "features = squinky_lexical[feature_names]\n",
    "target = squinky_lexical[\"Formality\"]\n",
    "squinky_x, squinky_test_x, squinky_y, squinky_test_y = train_test_split(features, target, test_size=0.2, random_state=5)\n",
    "\n",
    "\n",
    "# Lexical\n",
    "squinky = pd.read_csv(\"..\\..\\data\\mturk_experiment_2.csv\",encoding=\"unicode escape\")\n",
    "lexical = pd.read_csv(\"..\\..\\data\\squinky_lexical.csv\",encoding=\"unicode escape\")\n",
    "squinky_lexical = pd.merge(squinky,lexical)\n",
    "print(len(squinky_lexical))\n",
    "feature_names = [\"Informativeness\",\"Implicature\",\"Length in Words\",\"Length in Characters\",\"F-score\",\"I-score\",\"Lexical Density\",\"Adjective Density\",\"Spellcheck Percentage\",\"Syllable Ratio\",\"Latinate vs Germanic\"]\n",
    "features = squinky_lexical[feature_names]\n",
    "target = squinky_lexical[\"Formality\"]\n",
    "lexical_x, lexical_test_x, lexical_y, lexical_test_y = train_test_split(features, target, test_size=0.2, random_state=5)\n",
    "\n",
    "# Scores\n",
    "squinky = pd.read_csv(\"..\\..\\data\\mturk_experiment_2.csv\",encoding=\"unicode escape\")\n",
    "scores = pd.read_csv(\"..\\..\\data\\squinky_scores.csv\",encoding=\"unicode escape\")\n",
    "squinky_scores = pd.merge(squinky,scores)\n",
    "feature_names = [\"Informativeness\",\"Implicature\",\"Length in Words\",\"Length in Characters\",\"F-score\",\"I-score\",\"Lexical Density\",\"ADF Score\",\"FK Grade Level\",\"Reading Time\",\"WF Score\"]\n",
    "features = squinky_scores[feature_names]\n",
    "target = squinky_scores[\"Formality\"]\n",
    "scores_x, scores_test_x, scores_y, scores_test_y = train_test_split(features, target, test_size=0.2, random_state=5)\n",
    "\n",
    "# Reading\n",
    "squinky = pd.read_csv(\"..\\..\\data\\mturk_experiment_2.csv\",encoding=\"unicode escape\")\n",
    "reading = pd.read_csv(\"../../data/squinky_reading.csv\",encoding=\"unicode escape\")\n",
    "squinky_reading = pd.merge(squinky,reading)\n",
    "feature_names = [\"Informativeness\",\"Implicature\",\"Length in Words\",\"Length in Characters\",\"F-score\",\"I-score\",\"Lexical Density\",\"FK Reading Ease\",\"FOG Scale\",\"SMOG Index\",\"ARI\",\"CL Index\",\"LW Formula\",\"DC Score\",\"Readability Consensus\",\"Spache Formula\"]\n",
    "features = squinky_reading[feature_names]\n",
    "target = squinky_reading[\"Formality\"]\n",
    "reading_x, reading_test_x, reading_y, reading_test_y = train_test_split(features, target, test_size=0.2, random_state=5)\n",
    "\n",
    "# NLP\n",
    "squinky = pd.read_csv(\"..\\..\\data\\mturk_experiment_2.csv\",encoding=\"unicode escape\")\n",
    "nlp = pd.read_csv(\"..\\..\\data\\\\squinky_nlp.csv\",encoding=\"unicode escape\")\n",
    "squinky_nlp = pd.merge(squinky,nlp)\n",
    "feature_names = [\"Informativeness\",\"Implicature\",\"Length in Words\",\"Length in Characters\",\"F-score\",\"I-score\",\"Lexical Density\",\"Cluster\",\"Topic\"]\n",
    "features = squinky_nlp[feature_names]\n",
    "target = squinky_nlp[\"Formality\"]\n",
    "nlp_x, nlp_test_x, nlp_y, nlp_test_y = train_test_split(features, target, test_size=0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Squinky</th>\n",
       "      <th>Lexical</th>\n",
       "      <th>Scores</th>\n",
       "      <th>Reading</th>\n",
       "      <th>NLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.433575</td>\n",
       "      <td>0.428670</td>\n",
       "      <td>0.461293</td>\n",
       "      <td>0.478031</td>\n",
       "      <td>0.381946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.502258</td>\n",
       "      <td>0.349013</td>\n",
       "      <td>0.439545</td>\n",
       "      <td>0.427462</td>\n",
       "      <td>0.457153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.360719</td>\n",
       "      <td>0.388665</td>\n",
       "      <td>0.293464</td>\n",
       "      <td>0.334329</td>\n",
       "      <td>0.327841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.675389</td>\n",
       "      <td>0.584717</td>\n",
       "      <td>0.703211</td>\n",
       "      <td>0.509633</td>\n",
       "      <td>0.644920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.345492</td>\n",
       "      <td>0.329183</td>\n",
       "      <td>0.225511</td>\n",
       "      <td>0.204206</td>\n",
       "      <td>0.295674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>0.564781</td>\n",
       "      <td>0.495993</td>\n",
       "      <td>0.496954</td>\n",
       "      <td>0.410332</td>\n",
       "      <td>0.616266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>0.291793</td>\n",
       "      <td>0.254691</td>\n",
       "      <td>0.243524</td>\n",
       "      <td>0.157768</td>\n",
       "      <td>0.256120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>0.490204</td>\n",
       "      <td>0.587809</td>\n",
       "      <td>0.463436</td>\n",
       "      <td>0.443917</td>\n",
       "      <td>0.463044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>0.152245</td>\n",
       "      <td>0.104076</td>\n",
       "      <td>0.124727</td>\n",
       "      <td>0.209405</td>\n",
       "      <td>0.093998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>0.710845</td>\n",
       "      <td>0.719272</td>\n",
       "      <td>0.711530</td>\n",
       "      <td>0.642690</td>\n",
       "      <td>0.682459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Squinky   Lexical    Scores   Reading       NLP\n",
       "0     0.433575  0.428670  0.461293  0.478031  0.381946\n",
       "1     0.502258  0.349013  0.439545  0.427462  0.457153\n",
       "2     0.360719  0.388665  0.293464  0.334329  0.327841\n",
       "3     0.675389  0.584717  0.703211  0.509633  0.644920\n",
       "4     0.345492  0.329183  0.225511  0.204206  0.295674\n",
       "...        ...       ...       ...       ...       ...\n",
       "1395  0.564781  0.495993  0.496954  0.410332  0.616266\n",
       "1396  0.291793  0.254691  0.243524  0.157768  0.256120\n",
       "1397  0.490204  0.587809  0.463436  0.443917  0.463044\n",
       "1398  0.152245  0.104076  0.124727  0.209405  0.093998\n",
       "1399  0.710845  0.719272  0.711530  0.642690  0.682459\n",
       "\n",
       "[1400 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear regression\n",
    "linear_regression = pd.DataFrame()\n",
    "\n",
    "# SQUINKY!\n",
    "lin_reg_squinky = list(linear_model.LinearRegression().fit(squinky_x, squinky_y).predict(squinky_test_x))\n",
    "df = pd.DataFrame()\n",
    "df[\"True\"] = list(squinky_test_y)\n",
    "df[\"Predicted\"] = lin_reg_squinky\n",
    "squared_error = []\n",
    "for index in df.index:\n",
    "    squared_error.append(mean_squared_error([df[\"True\"][index]],[df[\"Predicted\"][index]],squared=False))\n",
    "\n",
    "linear_regression[\"Squinky\"] = squared_error\n",
    "\n",
    "# Lexical\n",
    "lin_reg_lexical = list(linear_model.LinearRegression().fit(lexical_x, lexical_y).predict(lexical_test_x))\n",
    "df_lex = pd.DataFrame()\n",
    "df_lex[\"True\"] = list(lexical_test_y)\n",
    "df_lex[\"Predicted\"] = lin_reg_lexical\n",
    "squared_error = []\n",
    "for index in df_lex.index:\n",
    "    squared_error.append(mean_squared_error([df_lex[\"True\"][index]],[df_lex[\"Predicted\"][index]],squared=False))\n",
    "\n",
    "linear_regression[\"Lexical\"] = squared_error\n",
    "\n",
    "# Scores\n",
    "lin_reg_scores = list(linear_model.LinearRegression().fit(scores_x, scores_y).predict(scores_test_x))\n",
    "df_score = pd.DataFrame()\n",
    "df_score[\"True\"] = list(scores_test_y)\n",
    "df_score[\"Predicted\"] = lin_reg_scores\n",
    "squared_error = []\n",
    "for index in df_score.index:\n",
    "    squared_error.append(mean_squared_error([df_score[\"True\"][index]],[df_score[\"Predicted\"][index]],squared=False))\n",
    "\n",
    "linear_regression[\"Scores\"] = squared_error\n",
    "\n",
    "# Reading\n",
    "lin_reg_reading = list(linear_model.LinearRegression().fit(reading_x, reading_y).predict(reading_test_x))\n",
    "df = pd.DataFrame()\n",
    "df[\"True\"] = list(reading_test_y)\n",
    "df[\"Predicted\"] = lin_reg_reading\n",
    "squared_error = []\n",
    "for index in df.index:\n",
    "    squared_error.append(mean_squared_error([df[\"True\"][index]],[df[\"Predicted\"][index]],squared=False))\n",
    "\n",
    "linear_regression[\"Reading\"] = squared_error\n",
    "\n",
    "# NLP\n",
    "lin_reg_nlp = list(linear_model.LinearRegression().fit(nlp_x, nlp_y).predict(nlp_test_x))\n",
    "df = pd.DataFrame()\n",
    "df[\"True\"] = list(nlp_test_y)\n",
    "df[\"Predicted\"] = lin_reg_nlp\n",
    "squared_error = []\n",
    "for index in df.index:\n",
    "    squared_error.append(mean_squared_error([df[\"True\"][index]],[df[\"Predicted\"][index]],squared=False))\n",
    "\n",
    "linear_regression[\"NLP\"] = squared_error\n",
    "\n",
    "linear_regression\n",
    "\n",
    "linear_regression_significances = pd.DataFrame()\n",
    "t, p = stats.ttest_ind(linear_regression[\"Squinky\"], linear_regression[\"Lexical\"])\n",
    "linear_regression_significances[\"Lexical - Linear Regression\"] = [p,p<0.05]\n",
    "\n",
    "t, p = stats.ttest_ind(linear_regression[\"Squinky\"], linear_regression[\"Scores\"])\n",
    "linear_regression_significances[\"Scores - Linear Regression\"] = [p,p<0.05]\n",
    "\n",
    "t, p = stats.ttest_ind(linear_regression[\"Squinky\"], linear_regression[\"Reading\"])\n",
    "linear_regression_significances[\"Reading - Linear Regression\"] = [p,p<0.05]\n",
    "\n",
    "t, p = stats.ttest_ind(linear_regression[\"Squinky\"], linear_regression[\"NLP\"])\n",
    "linear_regression_significances[\"NLP - Linear Regression\"] = [p,p<0.05]\n",
    "\n",
    "linear_regression_significances.T\n",
    "linear_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lexical - Linear Regression</th>\n",
       "      <td>0.450746</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scores - Linear Regression</th>\n",
       "      <td>0.893517</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reading - Linear Regression</th>\n",
       "      <td>0.581023</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLP - Linear Regression</th>\n",
       "      <td>0.99125</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lexical - Ridge Regression</th>\n",
       "      <td>0.450654</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scores - Ridge Regression</th>\n",
       "      <td>0.961244</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reading - Ridge Regression</th>\n",
       "      <td>0.581015</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLP - Ridge Regression</th>\n",
       "      <td>0.991209</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0      1\n",
       "Lexical - Linear Regression  0.450746  False\n",
       "Scores - Linear Regression   0.893517  False\n",
       "Reading - Linear Regression  0.581023  False\n",
       "NLP - Linear Regression       0.99125  False\n",
       "Lexical - Ridge Regression   0.450654  False\n",
       "Scores - Ridge Regression    0.961244  False\n",
       "Reading - Ridge Regression   0.581015  False\n",
       "NLP - Ridge Regression       0.991209  False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear regression\n",
    "linear_regression = pd.DataFrame()\n",
    "\n",
    "# SQUINKY!\n",
    "lin_reg_squinky = list(linear_model.Ridge().fit(squinky_x, squinky_y).predict(squinky_test_x))\n",
    "df = pd.DataFrame()\n",
    "df[\"True\"] = list(squinky_test_y)\n",
    "df[\"Predicted\"] = lin_reg_squinky\n",
    "squared_error = []\n",
    "for index in df.index:\n",
    "    squared_error.append(mean_squared_error([df[\"True\"][index]],[df[\"Predicted\"][index]],squared=False))\n",
    "\n",
    "linear_regression[\"Squinky\"] = squared_error\n",
    "\n",
    "# Lexical\n",
    "lin_reg_lexical = list(linear_model.Ridge().fit(lexical_x, lexical_y).predict(lexical_test_x))\n",
    "df_lex = pd.DataFrame()\n",
    "df_lex[\"True\"] = list(lexical_test_y)\n",
    "df_lex[\"Predicted\"] = lin_reg_lexical\n",
    "squared_error = []\n",
    "for index in df_lex.index:\n",
    "    squared_error.append(mean_squared_error([df_lex[\"True\"][index]],[df_lex[\"Predicted\"][index]],squared=False))\n",
    "\n",
    "linear_regression[\"Lexical\"] = squared_error\n",
    "\n",
    "# Scores\n",
    "lin_reg_scores = list(linear_model.Ridge().fit(scores_x, scores_y).predict(scores_test_x))\n",
    "df_score = pd.DataFrame()\n",
    "df_score[\"True\"] = list(scores_test_y)\n",
    "df_score[\"Predicted\"] = lin_reg_scores\n",
    "squared_error = []\n",
    "for index in df_score.index:\n",
    "    squared_error.append(mean_squared_error([df_score[\"True\"][index]],[df_score[\"Predicted\"][index]],squared=False))\n",
    "\n",
    "linear_regression[\"Scores\"] = squared_error\n",
    "\n",
    "# Reading\n",
    "lin_reg_reading = list(linear_model.Ridge().fit(reading_x, reading_y).predict(reading_test_x))\n",
    "df = pd.DataFrame()\n",
    "df[\"True\"] = list(reading_test_y)\n",
    "df[\"Predicted\"] = lin_reg_reading\n",
    "squared_error = []\n",
    "for index in df.index:\n",
    "    squared_error.append(mean_squared_error([df[\"True\"][index]],[df[\"Predicted\"][index]],squared=False))\n",
    "\n",
    "linear_regression[\"Reading\"] = squared_error\n",
    "\n",
    "# NLP\n",
    "lin_reg_nlp = list(linear_model.Ridge().fit(nlp_x, nlp_y).predict(nlp_test_x))\n",
    "df = pd.DataFrame()\n",
    "df[\"True\"] = list(nlp_test_y)\n",
    "df[\"Predicted\"] = lin_reg_nlp\n",
    "squared_error = []\n",
    "for index in df.index:\n",
    "    squared_error.append(mean_squared_error([df[\"True\"][index]],[df[\"Predicted\"][index]],squared=False))\n",
    "\n",
    "linear_regression[\"NLP\"] = squared_error\n",
    "\n",
    "linear_regression\n",
    "\n",
    "t, p = stats.ttest_ind(linear_regression[\"Squinky\"], linear_regression[\"Lexical\"])\n",
    "linear_regression_significances[\"Lexical - Ridge Regression\"] = [p,p<0.05]\n",
    "\n",
    "t, p = stats.ttest_ind(linear_regression[\"Squinky\"], linear_regression[\"Scores\"])\n",
    "linear_regression_significances[\"Scores - Ridge Regression\"] = [p,p<0.05]\n",
    "\n",
    "t, p = stats.ttest_ind(linear_regression[\"Squinky\"], linear_regression[\"Reading\"])\n",
    "linear_regression_significances[\"Reading - Ridge Regression\"] = [p,p<0.05]\n",
    "\n",
    "t, p = stats.ttest_ind(linear_regression[\"Squinky\"], linear_regression[\"NLP\"])\n",
    "linear_regression_significances[\"NLP - Ridge Regression\"] = [p,p<0.05]\n",
    "\n",
    "linear_regression_significances.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lexical - Linear Regression</th>\n",
       "      <td>0.450746</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scores - Linear Regression</th>\n",
       "      <td>0.893517</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reading - Linear Regression</th>\n",
       "      <td>0.581023</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLP - Linear Regression</th>\n",
       "      <td>0.99125</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lexical - Ridge Regression</th>\n",
       "      <td>0.450654</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scores - Ridge Regression</th>\n",
       "      <td>0.961244</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reading - Ridge Regression</th>\n",
       "      <td>0.581015</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLP - Ridge Regression</th>\n",
       "      <td>0.991209</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lexical - Lasso Regression</th>\n",
       "      <td>0.433401</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scores - Lasso Regression</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reading - Lasso Regression</th>\n",
       "      <td>0.702224</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLP - Lasso Regression</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0      1\n",
       "Lexical - Linear Regression  0.450746  False\n",
       "Scores - Linear Regression   0.893517  False\n",
       "Reading - Linear Regression  0.581023  False\n",
       "NLP - Linear Regression       0.99125  False\n",
       "Lexical - Ridge Regression   0.450654  False\n",
       "Scores - Ridge Regression    0.961244  False\n",
       "Reading - Ridge Regression   0.581015  False\n",
       "NLP - Ridge Regression       0.991209  False\n",
       "Lexical - Lasso Regression   0.433401  False\n",
       "Scores - Lasso Regression         1.0  False\n",
       "Reading - Lasso Regression   0.702224  False\n",
       "NLP - Lasso Regression            1.0  False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear regression\n",
    "linear_regression = pd.DataFrame()\n",
    "\n",
    "# SQUINKY!\n",
    "lin_reg_squinky = list(linear_model.Lasso().fit(squinky_x, squinky_y).predict(squinky_test_x))\n",
    "df = pd.DataFrame()\n",
    "df[\"True\"] = list(squinky_test_y)\n",
    "df[\"Predicted\"] = lin_reg_squinky\n",
    "squared_error = []\n",
    "for index in df.index:\n",
    "    squared_error.append(mean_squared_error([df[\"True\"][index]],[df[\"Predicted\"][index]],squared=False))\n",
    "\n",
    "linear_regression[\"Squinky\"] = squared_error\n",
    "\n",
    "# Lexical\n",
    "lin_reg_lexical = list(linear_model.Lasso().fit(lexical_x, lexical_y).predict(lexical_test_x))\n",
    "df_lex = pd.DataFrame()\n",
    "df_lex[\"True\"] = list(lexical_test_y)\n",
    "df_lex[\"Predicted\"] = lin_reg_lexical\n",
    "squared_error = []\n",
    "for index in df_lex.index:\n",
    "    squared_error.append(mean_squared_error([df_lex[\"True\"][index]],[df_lex[\"Predicted\"][index]],squared=False))\n",
    "\n",
    "linear_regression[\"Lexical\"] = squared_error\n",
    "\n",
    "# Scores\n",
    "lin_reg_scores = list(linear_model.Lasso().fit(scores_x, scores_y).predict(scores_test_x))\n",
    "df_score = pd.DataFrame()\n",
    "df_score[\"True\"] = list(scores_test_y)\n",
    "df_score[\"Predicted\"] = lin_reg_scores\n",
    "squared_error = []\n",
    "for index in df_score.index:\n",
    "    squared_error.append(mean_squared_error([df_score[\"True\"][index]],[df_score[\"Predicted\"][index]],squared=False))\n",
    "\n",
    "linear_regression[\"Scores\"] = squared_error\n",
    "\n",
    "# Reading\n",
    "lin_reg_reading = list(linear_model.Lasso().fit(reading_x, reading_y).predict(reading_test_x))\n",
    "df = pd.DataFrame()\n",
    "df[\"True\"] = list(reading_test_y)\n",
    "df[\"Predicted\"] = lin_reg_reading\n",
    "squared_error = []\n",
    "for index in df.index:\n",
    "    squared_error.append(mean_squared_error([df[\"True\"][index]],[df[\"Predicted\"][index]],squared=False))\n",
    "\n",
    "linear_regression[\"Reading\"] = squared_error\n",
    "\n",
    "# NLP\n",
    "lin_reg_nlp = list(linear_model.Lasso().fit(nlp_x, nlp_y).predict(nlp_test_x))\n",
    "df = pd.DataFrame()\n",
    "df[\"True\"] = list(nlp_test_y)\n",
    "df[\"Predicted\"] = lin_reg_nlp\n",
    "squared_error = []\n",
    "for index in df.index:\n",
    "    squared_error.append(mean_squared_error([df[\"True\"][index]],[df[\"Predicted\"][index]],squared=False))\n",
    "\n",
    "linear_regression[\"NLP\"] = squared_error\n",
    "\n",
    "linear_regression\n",
    "\n",
    "t, p = stats.ttest_ind(linear_regression[\"Squinky\"], linear_regression[\"Lexical\"])\n",
    "linear_regression_significances[\"Lexical - Lasso Regression\"] = [p,p<0.05]\n",
    "\n",
    "t, p = stats.ttest_ind(linear_regression[\"Squinky\"], linear_regression[\"Scores\"])\n",
    "linear_regression_significances[\"Scores - Lasso Regression\"] = [p,p<0.05]\n",
    "\n",
    "t, p = stats.ttest_ind(linear_regression[\"Squinky\"], linear_regression[\"Reading\"])\n",
    "linear_regression_significances[\"Reading - Lasso Regression\"] = [p,p<0.05]\n",
    "\n",
    "t, p = stats.ttest_ind(linear_regression[\"Squinky\"], linear_regression[\"NLP\"])\n",
    "linear_regression_significances[\"NLP - Lasso Regression\"] = [p,p<0.05]\n",
    "\n",
    "linear_regression_significances.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jack-\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "C:\\Users\\jack-\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "C:\\Users\\jack-\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "C:\\Users\\jack-\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "C:\\Users\\jack-\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lexical - Linear Regression</th>\n",
       "      <td>0.450746</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scores - Linear Regression</th>\n",
       "      <td>0.893517</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reading - Linear Regression</th>\n",
       "      <td>0.581023</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLP - Linear Regression</th>\n",
       "      <td>0.99125</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lexical - Ridge Regression</th>\n",
       "      <td>0.450654</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scores - Ridge Regression</th>\n",
       "      <td>0.961244</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reading - Ridge Regression</th>\n",
       "      <td>0.581015</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLP - Ridge Regression</th>\n",
       "      <td>0.991209</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lexical - Lasso Regression</th>\n",
       "      <td>0.433401</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scores - Lasso Regression</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reading - Lasso Regression</th>\n",
       "      <td>0.702224</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLP - Lasso Regression</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lexical - LARS Lasso Regression</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scores - LARS Lasso Regression</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reading - LARS Lasso Regression</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLP - LARS Lasso Regression</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        0      1\n",
       "Lexical - Linear Regression      0.450746  False\n",
       "Scores - Linear Regression       0.893517  False\n",
       "Reading - Linear Regression      0.581023  False\n",
       "NLP - Linear Regression           0.99125  False\n",
       "Lexical - Ridge Regression       0.450654  False\n",
       "Scores - Ridge Regression        0.961244  False\n",
       "Reading - Ridge Regression       0.581015  False\n",
       "NLP - Ridge Regression           0.991209  False\n",
       "Lexical - Lasso Regression       0.433401  False\n",
       "Scores - Lasso Regression             1.0  False\n",
       "Reading - Lasso Regression       0.702224  False\n",
       "NLP - Lasso Regression                1.0  False\n",
       "Lexical - LARS Lasso Regression       1.0  False\n",
       "Scores - LARS Lasso Regression        1.0  False\n",
       "Reading - LARS Lasso Regression       1.0  False\n",
       "NLP - LARS Lasso Regression           1.0  False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear regression\n",
    "linear_regression = pd.DataFrame()\n",
    "\n",
    "# SQUINKY!\n",
    "lin_reg_squinky = list(linear_model.LassoLars().fit(squinky_x, squinky_y).predict(squinky_test_x))\n",
    "df = pd.DataFrame()\n",
    "df[\"True\"] = list(squinky_test_y)\n",
    "df[\"Predicted\"] = lin_reg_squinky\n",
    "squared_error = []\n",
    "for index in df.index:\n",
    "    squared_error.append(mean_squared_error([df[\"True\"][index]],[df[\"Predicted\"][index]],squared=False))\n",
    "\n",
    "linear_regression[\"Squinky\"] = squared_error\n",
    "\n",
    "# Lexical\n",
    "lin_reg_lexical = list(linear_model.LassoLars().fit(lexical_x, lexical_y).predict(lexical_test_x))\n",
    "df_lex = pd.DataFrame()\n",
    "df_lex[\"True\"] = list(lexical_test_y)\n",
    "df_lex[\"Predicted\"] = lin_reg_lexical\n",
    "squared_error = []\n",
    "for index in df_lex.index:\n",
    "    squared_error.append(mean_squared_error([df_lex[\"True\"][index]],[df_lex[\"Predicted\"][index]],squared=False))\n",
    "\n",
    "linear_regression[\"Lexical\"] = squared_error\n",
    "\n",
    "# Scores\n",
    "lin_reg_scores = list(linear_model.LassoLars().fit(scores_x, scores_y).predict(scores_test_x))\n",
    "df_score = pd.DataFrame()\n",
    "df_score[\"True\"] = list(scores_test_y)\n",
    "df_score[\"Predicted\"] = lin_reg_scores\n",
    "squared_error = []\n",
    "for index in df_score.index:\n",
    "    squared_error.append(mean_squared_error([df_score[\"True\"][index]],[df_score[\"Predicted\"][index]],squared=False))\n",
    "\n",
    "linear_regression[\"Scores\"] = squared_error\n",
    "\n",
    "# Reading\n",
    "lin_reg_reading = list(linear_model.LassoLars().fit(reading_x, reading_y).predict(reading_test_x))\n",
    "df = pd.DataFrame()\n",
    "df[\"True\"] = list(reading_test_y)\n",
    "df[\"Predicted\"] = lin_reg_reading\n",
    "squared_error = []\n",
    "for index in df.index:\n",
    "    squared_error.append(mean_squared_error([df[\"True\"][index]],[df[\"Predicted\"][index]],squared=False))\n",
    "\n",
    "linear_regression[\"Reading\"] = squared_error\n",
    "\n",
    "# NLP\n",
    "lin_reg_nlp = list(linear_model.LassoLars().fit(nlp_x, nlp_y).predict(nlp_test_x))\n",
    "df = pd.DataFrame()\n",
    "df[\"True\"] = list(nlp_test_y)\n",
    "df[\"Predicted\"] = lin_reg_nlp\n",
    "squared_error = []\n",
    "for index in df.index:\n",
    "    squared_error.append(mean_squared_error([df[\"True\"][index]],[df[\"Predicted\"][index]],squared=False))\n",
    "\n",
    "linear_regression[\"NLP\"] = squared_error\n",
    "\n",
    "linear_regression\n",
    "\n",
    "t, p = stats.ttest_ind(linear_regression[\"Squinky\"], linear_regression[\"Lexical\"])\n",
    "linear_regression_significances[\"Lexical - LARS Lasso Regression\"] = [p,p<0.05]\n",
    "\n",
    "t, p = stats.ttest_ind(linear_regression[\"Squinky\"], linear_regression[\"Scores\"])\n",
    "linear_regression_significances[\"Scores - LARS Lasso Regression\"] = [p,p<0.05]\n",
    "\n",
    "t, p = stats.ttest_ind(linear_regression[\"Squinky\"], linear_regression[\"Reading\"])\n",
    "linear_regression_significances[\"Reading - LARS Lasso Regression\"] = [p,p<0.05]\n",
    "\n",
    "t, p = stats.ttest_ind(linear_regression[\"Squinky\"], linear_regression[\"NLP\"])\n",
    "linear_regression_significances[\"NLP - LARS Lasso Regression\"] = [p,p<0.05]\n",
    "\n",
    "linear_regression_significances.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lexical - Linear Regression</th>\n",
       "      <td>0.450746</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scores - Linear Regression</th>\n",
       "      <td>0.893517</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reading - Linear Regression</th>\n",
       "      <td>0.581023</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLP - Linear Regression</th>\n",
       "      <td>0.99125</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lexical - Ridge Regression</th>\n",
       "      <td>0.450654</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scores - Ridge Regression</th>\n",
       "      <td>0.961244</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reading - Ridge Regression</th>\n",
       "      <td>0.581015</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLP - Ridge Regression</th>\n",
       "      <td>0.991209</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lexical - Lasso Regression</th>\n",
       "      <td>0.433401</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scores - Lasso Regression</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reading - Lasso Regression</th>\n",
       "      <td>0.702224</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLP - Lasso Regression</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lexical - LARS Lasso Regression</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scores - LARS Lasso Regression</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reading - LARS Lasso Regression</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLP - LARS Lasso Regression</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lexical - Bayesian Ridge Regression</th>\n",
       "      <td>0.450507</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scores - Bayesian Ridge Regression</th>\n",
       "      <td>0.926812</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reading - Bayesian Ridge Regression</th>\n",
       "      <td>0.584208</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLP - Bayesian Ridge Regression</th>\n",
       "      <td>0.991429</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            0      1\n",
       "Lexical - Linear Regression          0.450746  False\n",
       "Scores - Linear Regression           0.893517  False\n",
       "Reading - Linear Regression          0.581023  False\n",
       "NLP - Linear Regression               0.99125  False\n",
       "Lexical - Ridge Regression           0.450654  False\n",
       "Scores - Ridge Regression            0.961244  False\n",
       "Reading - Ridge Regression           0.581015  False\n",
       "NLP - Ridge Regression               0.991209  False\n",
       "Lexical - Lasso Regression           0.433401  False\n",
       "Scores - Lasso Regression                 1.0  False\n",
       "Reading - Lasso Regression           0.702224  False\n",
       "NLP - Lasso Regression                    1.0  False\n",
       "Lexical - LARS Lasso Regression           1.0  False\n",
       "Scores - LARS Lasso Regression            1.0  False\n",
       "Reading - LARS Lasso Regression           1.0  False\n",
       "NLP - LARS Lasso Regression               1.0  False\n",
       "Lexical - Bayesian Ridge Regression  0.450507  False\n",
       "Scores - Bayesian Ridge Regression   0.926812  False\n",
       "Reading - Bayesian Ridge Regression  0.584208  False\n",
       "NLP - Bayesian Ridge Regression      0.991429  False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear regression\n",
    "linear_regression = pd.DataFrame()\n",
    "\n",
    "# SQUINKY!\n",
    "lin_reg_squinky = list(linear_model.BayesianRidge().fit(squinky_x, squinky_y).predict(squinky_test_x))\n",
    "df = pd.DataFrame()\n",
    "df[\"True\"] = list(squinky_test_y)\n",
    "df[\"Predicted\"] = lin_reg_squinky\n",
    "squared_error = []\n",
    "for index in df.index:\n",
    "    squared_error.append(mean_squared_error([df[\"True\"][index]],[df[\"Predicted\"][index]],squared=False))\n",
    "\n",
    "linear_regression[\"Squinky\"] = squared_error\n",
    "\n",
    "# Lexical\n",
    "lin_reg_lexical = list(linear_model.BayesianRidge().fit(lexical_x, lexical_y).predict(lexical_test_x))\n",
    "df_lex = pd.DataFrame()\n",
    "df_lex[\"True\"] = list(lexical_test_y)\n",
    "df_lex[\"Predicted\"] = lin_reg_lexical\n",
    "squared_error = []\n",
    "for index in df_lex.index:\n",
    "    squared_error.append(mean_squared_error([df_lex[\"True\"][index]],[df_lex[\"Predicted\"][index]],squared=False))\n",
    "\n",
    "linear_regression[\"Lexical\"] = squared_error\n",
    "\n",
    "# Scores\n",
    "lin_reg_scores = list(linear_model.BayesianRidge().fit(scores_x, scores_y).predict(scores_test_x))\n",
    "df_score = pd.DataFrame()\n",
    "df_score[\"True\"] = list(scores_test_y)\n",
    "df_score[\"Predicted\"] = lin_reg_scores\n",
    "squared_error = []\n",
    "for index in df_score.index:\n",
    "    squared_error.append(mean_squared_error([df_score[\"True\"][index]],[df_score[\"Predicted\"][index]],squared=False))\n",
    "\n",
    "linear_regression[\"Scores\"] = squared_error\n",
    "\n",
    "# Reading\n",
    "lin_reg_reading = list(linear_model.BayesianRidge().fit(reading_x, reading_y).predict(reading_test_x))\n",
    "df = pd.DataFrame()\n",
    "df[\"True\"] = list(reading_test_y)\n",
    "df[\"Predicted\"] = lin_reg_reading\n",
    "squared_error = []\n",
    "for index in df.index:\n",
    "    squared_error.append(mean_squared_error([df[\"True\"][index]],[df[\"Predicted\"][index]],squared=False))\n",
    "\n",
    "linear_regression[\"Reading\"] = squared_error\n",
    "\n",
    "# NLP\n",
    "lin_reg_nlp = list(linear_model.BayesianRidge().fit(nlp_x, nlp_y).predict(nlp_test_x))\n",
    "df = pd.DataFrame()\n",
    "df[\"True\"] = list(nlp_test_y)\n",
    "df[\"Predicted\"] = lin_reg_nlp\n",
    "squared_error = []\n",
    "for index in df.index:\n",
    "    squared_error.append(mean_squared_error([df[\"True\"][index]],[df[\"Predicted\"][index]],squared=False))\n",
    "\n",
    "linear_regression[\"NLP\"] = squared_error\n",
    "\n",
    "linear_regression\n",
    "\n",
    "t, p = stats.ttest_ind(linear_regression[\"Squinky\"], linear_regression[\"Lexical\"])\n",
    "linear_regression_significances[\"Lexical - Bayesian Ridge Regression\"] = [p,p<0.05]\n",
    "\n",
    "t, p = stats.ttest_ind(linear_regression[\"Squinky\"], linear_regression[\"Scores\"])\n",
    "linear_regression_significances[\"Scores - Bayesian Ridge Regression\"] = [p,p<0.05]\n",
    "\n",
    "t, p = stats.ttest_ind(linear_regression[\"Squinky\"], linear_regression[\"Reading\"])\n",
    "linear_regression_significances[\"Reading - Bayesian Ridge Regression\"] = [p,p<0.05]\n",
    "\n",
    "t, p = stats.ttest_ind(linear_regression[\"Squinky\"], linear_regression[\"NLP\"])\n",
    "linear_regression_significances[\"NLP - Bayesian Ridge Regression\"] = [p,p<0.05]\n",
    "\n",
    "linear_regression_significances.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lexical - Linear Regression</th>\n",
       "      <td>0.450746</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scores - Linear Regression</th>\n",
       "      <td>0.893517</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reading - Linear Regression</th>\n",
       "      <td>0.581023</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLP - Linear Regression</th>\n",
       "      <td>0.99125</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lexical - Ridge Regression</th>\n",
       "      <td>0.450654</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scores - Ridge Regression</th>\n",
       "      <td>0.961244</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reading - Ridge Regression</th>\n",
       "      <td>0.581015</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLP - Ridge Regression</th>\n",
       "      <td>0.991209</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lexical - Lasso Regression</th>\n",
       "      <td>0.433401</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scores - Lasso Regression</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reading - Lasso Regression</th>\n",
       "      <td>0.702224</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLP - Lasso Regression</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lexical - LARS Lasso Regression</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scores - LARS Lasso Regression</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reading - LARS Lasso Regression</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLP - LARS Lasso Regression</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lexical - Bayesian Ridge Regression</th>\n",
       "      <td>0.450507</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scores - Bayesian Ridge Regression</th>\n",
       "      <td>0.926812</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reading - Bayesian Ridge Regression</th>\n",
       "      <td>0.584208</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLP - Bayesian Ridge Regression</th>\n",
       "      <td>0.991429</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lexical - SGD Regression</th>\n",
       "      <td>0.269798</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scores - SGD Regression</th>\n",
       "      <td>0.50934</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reading - SGD Regression</th>\n",
       "      <td>0.440783</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLP - SGD Regression</th>\n",
       "      <td>0.495577</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            0      1\n",
       "Lexical - Linear Regression          0.450746  False\n",
       "Scores - Linear Regression           0.893517  False\n",
       "Reading - Linear Regression          0.581023  False\n",
       "NLP - Linear Regression               0.99125  False\n",
       "Lexical - Ridge Regression           0.450654  False\n",
       "Scores - Ridge Regression            0.961244  False\n",
       "Reading - Ridge Regression           0.581015  False\n",
       "NLP - Ridge Regression               0.991209  False\n",
       "Lexical - Lasso Regression           0.433401  False\n",
       "Scores - Lasso Regression                 1.0  False\n",
       "Reading - Lasso Regression           0.702224  False\n",
       "NLP - Lasso Regression                    1.0  False\n",
       "Lexical - LARS Lasso Regression           1.0  False\n",
       "Scores - LARS Lasso Regression            1.0  False\n",
       "Reading - LARS Lasso Regression           1.0  False\n",
       "NLP - LARS Lasso Regression               1.0  False\n",
       "Lexical - Bayesian Ridge Regression  0.450507  False\n",
       "Scores - Bayesian Ridge Regression   0.926812  False\n",
       "Reading - Bayesian Ridge Regression  0.584208  False\n",
       "NLP - Bayesian Ridge Regression      0.991429  False\n",
       "Lexical - SGD Regression             0.269798  False\n",
       "Scores - SGD Regression               0.50934  False\n",
       "Reading - SGD Regression             0.440783  False\n",
       "NLP - SGD Regression                 0.495577  False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear regression\n",
    "linear_regression = pd.DataFrame()\n",
    "\n",
    "# SQUINKY!\n",
    "lin_reg_squinky = list(linear_model.SGDRegressor().fit(scale(squinky_x), scale(squinky_y)).predict(scale(squinky_test_x)))\n",
    "df = pd.DataFrame()\n",
    "df[\"True\"] = list(squinky_test_y)\n",
    "df[\"Predicted\"] = lin_reg_squinky\n",
    "squared_error = []\n",
    "for index in df.index:\n",
    "    squared_error.append(mean_squared_error([df[\"True\"][index]],[df[\"Predicted\"][index]],squared=False))\n",
    "\n",
    "linear_regression[\"Squinky\"] = squared_error\n",
    "\n",
    "# Lexical\n",
    "lin_reg_lexical = list(linear_model.SGDRegressor().fit(scale(lexical_x), scale(lexical_y)).predict(scale(lexical_test_x)))\n",
    "df_lex = pd.DataFrame()\n",
    "df_lex[\"True\"] = list(lexical_test_y)\n",
    "df_lex[\"Predicted\"] = lin_reg_lexical\n",
    "squared_error = []\n",
    "for index in df_lex.index:\n",
    "    squared_error.append(mean_squared_error([df_lex[\"True\"][index]],[df_lex[\"Predicted\"][index]],squared=False))\n",
    "\n",
    "linear_regression[\"Lexical\"] = squared_error\n",
    "\n",
    "# Scores\n",
    "lin_reg_scores = list(linear_model.SGDRegressor().fit(scale(scores_x),scale(scores_y)).predict(scale(scores_test_x)))\n",
    "df_score = pd.DataFrame()\n",
    "df_score[\"True\"] = list(scores_test_y)\n",
    "df_score[\"Predicted\"] = lin_reg_scores\n",
    "squared_error = []\n",
    "for index in df_score.index:\n",
    "    squared_error.append(mean_squared_error([df_score[\"True\"][index]],[df_score[\"Predicted\"][index]],squared=False))\n",
    "\n",
    "linear_regression[\"Scores\"] = squared_error\n",
    "\n",
    "# Reading\n",
    "lin_reg_reading = list(linear_model.SGDRegressor().fit(scale(reading_x), scale(reading_y)).predict(scale(reading_test_x)))\n",
    "df = pd.DataFrame()\n",
    "df[\"True\"] = list(reading_test_y)\n",
    "df[\"Predicted\"] = lin_reg_reading\n",
    "squared_error = []\n",
    "for index in df.index:\n",
    "    squared_error.append(mean_squared_error([df[\"True\"][index]],[df[\"Predicted\"][index]],squared=False))\n",
    "\n",
    "linear_regression[\"Reading\"] = squared_error\n",
    "\n",
    "# NLP\n",
    "lin_reg_nlp = list(linear_model.SGDRegressor().fit(scale(nlp_x), scale(nlp_y)).predict(scale(nlp_test_x)))\n",
    "df = pd.DataFrame()\n",
    "df[\"True\"] = list(nlp_test_y)\n",
    "df[\"Predicted\"] = lin_reg_nlp\n",
    "squared_error = []\n",
    "for index in df.index:\n",
    "    squared_error.append(mean_squared_error([df[\"True\"][index]],[df[\"Predicted\"][index]],squared=False))\n",
    "\n",
    "linear_regression[\"NLP\"] = squared_error\n",
    "\n",
    "linear_regression\n",
    "\n",
    "t, p = stats.ttest_ind(linear_regression[\"Squinky\"], linear_regression[\"Lexical\"])\n",
    "linear_regression_significances[\"Lexical - SGD Regression\"] = [p,p<0.05]\n",
    "\n",
    "t, p = stats.ttest_ind(linear_regression[\"Squinky\"], linear_regression[\"Scores\"])\n",
    "linear_regression_significances[\"Scores - SGD Regression\"] = [p,p<0.05]\n",
    "\n",
    "t, p = stats.ttest_ind(linear_regression[\"Squinky\"], linear_regression[\"Reading\"])\n",
    "linear_regression_significances[\"Reading - SGD Regression\"] = [p,p<0.05]\n",
    "\n",
    "t, p = stats.ttest_ind(linear_regression[\"Squinky\"], linear_regression[\"NLP\"])\n",
    "linear_regression_significances[\"NLP - SGD Regression\"] = [p,p<0.05]\n",
    "\n",
    "linear_regression_significances.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "significances = linear_regression_significances.T\n",
    "significances.columns = [\"P-Value\",\"Significant\"]\n",
    "significances.to_csv(\"../../data/Traditional_model_side_information_significances.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a2292f7dadeec0b36dafabb7d1d8dd7b9b8b8f0665c515bec64e67bf9650aaf0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
